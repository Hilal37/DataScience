{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ahmad-CV.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRulecxtL61Z"
      },
      "source": [
        "Machine learning models are chosen based on their mean performance, often calculated using k-fold cross-validation. The algorithm with the best mean performance is expected to be better than those algorithms with worse mean performance. But sometimes the mean performance is caused by a statistical fluke. Therefore statistical hypothesis test helps in evaluating whether the difference in the mean performance between any two algorithms is real or not.\r\n",
        "\r\n",
        "The paired sample t-test is an uni variate test that tests for a significant difference between 2 related variables. Therefore we are using this test\r\n",
        "\r\n",
        "The null hypothesis of the test, is that there is no difference in the means between the samples. The rejection of the null hypothesis indicates that there is enough evidence that the sample means are different."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYNbbgmVSaQf"
      },
      "source": [
        "##Comparing with and without MLSMOTE for a Neural Network Model\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w700HXA-rsnu"
      },
      "source": [
        "# study of mlp learning curves given different number of layers for multi-class classification\r\n",
        "from pandas import read_csv\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.optimizers import SGD\r\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score, \\\r\n",
        "    confusion_matrix\r\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RepeatedKFold, learning_curve, GridSearchCV\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.python.keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxpQACj_rxjf"
      },
      "source": [
        "X = read_csv('/content/drive/MyDrive/train_features.csv')\r\n",
        "X = np.asarray(X)[:,4:]     #4\r\n",
        "\r\n",
        "y = read_csv('/content/drive/MyDrive/train_targets_scored.csv')\r\n",
        "y = np.asarray(y)[:,1:]     #1\r\n",
        "\r\n",
        "n_layers = [64, 128, 64]    #[120, 84]\r\n",
        "X_shape, y_shape = X.shape[1], y.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBwwhGNgrvD_"
      },
      "source": [
        "def get_model(learn_rate=0.0001,):\r\n",
        "    n_input, n_classes = X_shape, y_shape\r\n",
        "    model = Sequential()\r\n",
        "\r\n",
        "    model.add(Dense(n_layers[0], input_dim=n_input, activation='relu'))\r\n",
        "    for nb_neurons in n_layers[1:len(n_layers)]:\r\n",
        "        model.add(Dense(nb_neurons, activation='relu'))\r\n",
        "    model.add(Dense(n_classes, activation='sigmoid'))\r\n",
        "\r\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po8AozlVrz_H"
      },
      "source": [
        "model = KerasClassifier(build_fn=get_model, epochs=150, batch_size=10, verbose=0)\r\n",
        "# evaluate using 10-fold cross validation\r\n",
        "kfold1 = RepeatedKFold(n_splits=10, n_repeats=1, random_state=123)\r\n",
        "results1 = cross_val_score(model, np.asarray(X).astype(np.float64), np.asarray(y).astype(np.float64), cv=kfold1)\r\n",
        "print(results1.mean())\r\n",
        "print(results1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oMVrUdj_cZ0"
      },
      "source": [
        "0.017257916973903775 \\\\\r\n",
        "[0.0247691  0.01553317 0.01889169 0.02980689 0.01469971 0.01385972\r\n",
        " 0.0100798  0.00713986 0.01805964 0.01973961]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhO1U9mQA2my"
      },
      "source": [
        "X = read_csv('/content/drive/MyDrive/train_features_mlsmote_200.csv')\r\n",
        "X = np.asarray(X)[:,4:]\r\n",
        "\r\n",
        "y = read_csv('/content/drive/MyDrive/train_targets_scored_mlsmote_200.csv')\r\n",
        "y = np.asarray(y)[:,1:]\r\n",
        "\r\n",
        "n_layers = [64, 128, 64]    #[120, 84]\r\n",
        "X_shape, y_shape = X.shape[1], y.shape[1]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jzmvnso-rVYf",
        "outputId": "11d9ac99-392a-49da-cd2a-e4abe3512011"
      },
      "source": [
        "model2 = KerasClassifier(build_fn=get_model, epochs=150, batch_size=10, verbose=0)\r\n",
        "# evaluate using 10-fold cross validation\r\n",
        "kfold = RepeatedKFold(n_splits=10, n_repeats=1, random_state=123)\r\n",
        "results = cross_val_score(model2, np.asarray(X).astype(np.float64), np.asarray(y).astype(np.float64), cv=kfold)\r\n",
        "print(results.mean())\r\n",
        "print(results)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5264029383659363\n",
            "[0.53111249 0.53991199 0.52671278 0.52482718 0.526564   0.52310592\n",
            " 0.52750707 0.5243634  0.51933354 0.52059102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRejnLMaq8Zp",
        "outputId": "b78ad480-97bc-45a6-c2b5-47dd658513a8"
      },
      "source": [
        "from scipy.stats import ttest_rel\r\n",
        "results1 = [0.0247691,  0.01553317, 0.01889169, 0.02980689, 0.01469971, 0.01385972, 0.0100798,  0.00713986, 0.01805964, 0.01973961]\r\n",
        "t, p = ttest_rel(results, results1)\r\n",
        "print(\"p-value:\", p)\r\n",
        "print(\"t-statistics:\", p)\r\n",
        "if p <= 0.01:\r\n",
        "    print('Since p<0.01, We reject the null-hypothesis that both models perform equally well on this dataset.')\r\n",
        "else:\r\n",
        "    print('Since p>0.01, we don\\'t reject the null hypothesis.')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p-value: 2.455344331889295e-17\n",
            "t-statistics: 2.455344331889295e-17\n",
            "Since p<0.01, We reject the null-hypothesis that both models perform equally well on this dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0O5YJwQGyyF"
      },
      "source": [
        "For alpha = 0.01, we have p-value < alpha, So, we can reject the null hypothesis  **H0**  with a confidence of 99%, and we can be 99% percent confident that applying MLSMOTE does improve performance, even if the performance numbers themselves are not great."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0Rb0CMTStJc"
      },
      "source": [
        "##Comparing a Neural Network Model with MLSMOTE to SVM with MLSMOTE\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjHiGyg-HYo7",
        "outputId": "866e130b-98de-499a-cb59-df4c8703e9a6"
      },
      "source": [
        "import pickle\r\n",
        "\r\n",
        "with open(\"/content/clf_mlsmote.pickle\", \"rb\") as f1:\r\n",
        "    svm_mlsmote = pickle.load(f1)\r\n",
        "idx_mlsmote = svm_mlsmote.best_index_\r\n",
        "cv_scores_svm_mlsmote = [svm_mlsmote.cv_results_[f\"split{i}_test_score\"][idx_mlsmote] for i in range(10)]\r\n",
        "scores_mlsmote = [x for x in cv_scores_svm_mlsmote if not np.isnan(x)]\r\n",
        "print(scores_mlsmote)\r\n",
        "t, p = ttest_rel(results[0:len(scores_mlsmote)], scores_mlsmote)\r\n",
        "print(\"p-value:\", p)\r\n",
        "print(\"t-statistics:\", p)\r\n",
        "if p <= 0.01:\r\n",
        "    print('Since p<0.01, We reject the null-hypothesis that both models perform equally well on this dataset.')\r\n",
        "else:\r\n",
        "    print('Since p>0.01, we don\\'t reject the null hypothesis.')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.36561743341404357, 0.3765133171912833, 0.3726392251815981, 0.3784503631961259, 0.3721549636803874, 0.3786924939467312]\n",
            "p-value: 1.1211805771823691e-07\n",
            "t-statistics: 1.1211805771823691e-07\n",
            "Since p<0.01, We reject the null-hypothesis that both models perform equally well on this dataset.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearSVC from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MultiOutputClassifier from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator GridSearchCV from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7p2cAJbJydj"
      },
      "source": [
        "For alpha = 0.01, we have p-value < alpha, So, we can reject the null hypothesis  **H0**  with a confidence of 99%, and we can be 99% percent confident that Neural Network does improve performance over SVM."
      ]
    }
  ]
}