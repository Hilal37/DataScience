{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP Phase 4 - Feature Selection with NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U75hoXEItMZ"
      },
      "source": [
        "**Neural Networks Hypothesis Testing before/after Feature Selection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_MlYvGj4qet"
      },
      "source": [
        "In this notebook, we're gonna do the hypothesis testing before and after feature selection, using neural networks.\r\n",
        "We will present the training and everything about the NN models we used earlier (so first part is gonna be the same code to recall old results), and then do the hypothesis testing one before and after models, after we train them on the data before and after feature selection. \r\n",
        "Also recall that using neural networks with FS (or without) had good accuracy but very bda fscore, and we don't consider this as good result so it's not actually the best model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAaiz2fqCNRo",
        "outputId": "a453e9c0-28af-468b-bba3-03f42929b589"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rd\n",
        "import pickle \n",
        "from sklearn.feature_selection import SelectKBest, chi2 ,f_classif\n",
        "!pip install learn2learn\n",
        "import learn2learn as l2l\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.model_selection import train_test_split, learning_curve, ShuffleSplit, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score \n",
        "from torch import nn, optim\n",
        "from sklearn.metrics import f1_score, log_loss, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "import torch\n",
        "!pip install skorch\n",
        "from skorch.classifier import NeuralNetClassifier"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting learn2learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/ce/544f86e91b61daaab7beae47c2639f59b373dec6334b3d0bfc5096e5d555/learn2learn-0.1.5.tar.gz (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (1.18.5)\n",
            "Requirement already satisfied: gym>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (0.17.3)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (0.8.1+cu101)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from learn2learn) (1.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from learn2learn) (2.23.0)\n",
            "Collecting gsutil\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/ec/d79f528581310ee5332626458e7a07c2d9c019448cc7979d8163860b4d34/gsutil-4.57.tar.gz (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 17.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from learn2learn) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym>=0.14.0->learn2learn) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.14.0->learn2learn) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.14.0->learn2learn) (1.5.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->learn2learn) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->learn2learn) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->learn2learn) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->learn2learn) (7.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->learn2learn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->learn2learn) (2.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (2.10)\n",
            "Collecting argcomplete>=1.9.4\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/d0/ee7fc6ceac8957196def9bfa3b955d02163058defd3edd51ef7b1ff2769e/argcomplete-1.12.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.6/dist-packages (from gsutil->learn2learn) (1.7)\n",
            "Collecting fasteners>=0.14.1\n",
            "  Downloading https://files.pythonhosted.org/packages/18/bd/55eb2d6397b9c0e263af9d091ebdb756b15756029b3cededf6461481bc63/fasteners-0.15-py2.py3-none-any.whl\n",
            "Collecting gcs-oauth2-boto-plugin>=2.7\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/ab/3cc16742de84b76aa328c4b9e09fbf88447027827c12fb3913c5907be23b/gcs-oauth2-boto-plugin-2.7.tar.gz\n",
            "Collecting google-apitools>=0.5.30\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/da/aefc4cf4c168b5d875344cd9dddc77e3a2d11986b630251af5ce47dd2843/google-apitools-0.5.31.tar.gz (173kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 44.5MB/s \n",
            "\u001b[?25hCollecting httplib2>=0.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/ad/d9d9331850ea5bd4f5cb8c650c0bfa119a4abd6b0ad7c45b6506bc979fc0/httplib2-0.18.1-py3-none-any.whl (95kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.2MB/s \n",
            "\u001b[?25hCollecting google-reauth>=0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/69/e1/67ffaa3a645b86318ce30717af7145070ebccec5eef5c623ae08b86129b8/google_reauth-0.1.1-py2.py3-none-any.whl\n",
            "Collecting mock==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.9MB/s \n",
            "\u001b[?25hCollecting monotonic>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/aa/063eca6a416f397bd99552c534c6d11d57f58f2e94c14780f3bbf818c4cf/monotonic-1.5-py2.py3-none-any.whl\n",
            "Collecting pyOpenSSL>=0.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/86/e21398551956735fef8f7883908771445878ccb16cd17c0896176419cd75/pyOpenSSL-20.0.0-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.7MB/s \n",
            "\u001b[?25hCollecting retry_decorator>=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/6e/e6/bedc75b264cbcbf6e6d0e5071d96d739f540fc09be31744a7a8824c02a8e/retry_decorator-1.1.1.tar.gz\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from gsutil->learn2learn) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata<4,>=0.23; python_version == \"3.6\" in /usr/local/lib/python3.6/dist-packages (from argcomplete>=1.9.4->gsutil->learn2learn) (3.1.1)\n",
            "Collecting boto>=2.29.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from gcs-oauth2-boto-plugin>=2.7->gsutil->learn2learn) (4.1.3)\n",
            "Collecting pyu2f\n",
            "  Downloading https://files.pythonhosted.org/packages/29/b5/c1209e6cb77647bc2c9a6a1a953355720f34f3b006b725e303c70f3c0786/pyu2f-0.1.5.tar.gz\n",
            "Collecting pbr>=0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 45.2MB/s \n",
            "\u001b[?25hCollecting cryptography>=3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/de/7054df0620b5411ba45480f0261e1fb66a53f3db31b28e3aa52c026e72d9/cryptography-3.3.1-cp36-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 46.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata<4,>=0.23; python_version == \"3.6\"->argcomplete>=1.9.4->gsutil->learn2learn) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=2.2.0->gcs-oauth2-boto-plugin>=2.7->gsutil->learn2learn) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=2.2.0->gcs-oauth2-boto-plugin>=2.7->gsutil->learn2learn) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=2.2.0->gcs-oauth2-boto-plugin>=2.7->gsutil->learn2learn) (0.2.8)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.6/dist-packages (from cryptography>=3.2->pyOpenSSL>=0.13->gsutil->learn2learn) (1.14.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.12->cryptography>=3.2->pyOpenSSL>=0.13->gsutil->learn2learn) (2.20)\n",
            "Building wheels for collected packages: learn2learn, gsutil, gcs-oauth2-boto-plugin, google-apitools, retry-decorator, pyu2f\n",
            "  Building wheel for learn2learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for learn2learn: filename=learn2learn-0.1.5-cp36-cp36m-linux_x86_64.whl size=915668 sha256=0589d62895687ca7a08e16867df6d555ef6c53d057b13e8360ca98671b01befc\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/44/11/9d755af86d74f353dc7e56d5e75668e4ae7f5bf8c7d74f1f7e\n",
            "  Building wheel for gsutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gsutil: filename=gsutil-4.57-cp36-none-any.whl size=3340433 sha256=538c3d3a2ffac54f617b3f663421dab7e51169d75713dfe51ff608eb86251160\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/18/1c/9f12d053973060e235d1ede1bf4dd530d30b72c572dec0021a\n",
            "  Building wheel for gcs-oauth2-boto-plugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gcs-oauth2-boto-plugin: filename=gcs_oauth2_boto_plugin-2.7-cp36-none-any.whl size=23203 sha256=e29332a61953edebabb637e1f000f40206631e97e4ec576e87ab48dcafb02c45\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/6b/7c/bd86832ceb17e0ae3d362c44f461832452eeaacddfcf9128ee\n",
            "  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-apitools: filename=google_apitools-0.5.31-cp36-none-any.whl size=131043 sha256=c2c3deb6c7b5af1e014b1414e1eb7b0bda252294b3b7399977072b74e2778a3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/43/31/09a9dad88d3aec6fed2d63bd35dfc532fca372e2edec5af5bf\n",
            "  Building wheel for retry-decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for retry-decorator: filename=retry_decorator-1.1.1-py2.py3-none-any.whl size=3639 sha256=23a93eac5867acffb4103479e194cb42ac141ff3b97ee189088fb5d8910165ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/70/30/4af820545aa19a0d96f969ef5ecebbb9743fd89cf00db43273\n",
            "  Building wheel for pyu2f (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyu2f: filename=pyu2f-0.1.5-cp36-none-any.whl size=39389 sha256=0f7356b45a634b024e5d57bf18980229472c00ee70054d1cc9d9f6bf0538846c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/74/4d/2a07cf37327596c99f570ebe983a9843cda0278ca36a27ad9d\n",
            "Successfully built learn2learn gsutil gcs-oauth2-boto-plugin google-apitools retry-decorator pyu2f\n",
            "Installing collected packages: argcomplete, monotonic, fasteners, boto, pyu2f, google-reauth, httplib2, cryptography, pyOpenSSL, retry-decorator, gcs-oauth2-boto-plugin, google-apitools, pbr, mock, gsutil, learn2learn\n",
            "  Found existing installation: httplib2 0.17.4\n",
            "    Uninstalling httplib2-0.17.4:\n",
            "      Successfully uninstalled httplib2-0.17.4\n",
            "Successfully installed argcomplete-1.12.2 boto-2.49.0 cryptography-3.3.1 fasteners-0.15 gcs-oauth2-boto-plugin-2.7 google-apitools-0.5.31 google-reauth-0.1.1 gsutil-4.57 httplib2-0.18.1 learn2learn-0.1.5 mock-2.0.0 monotonic-1.5 pbr-5.5.1 pyOpenSSL-20.0.0 pyu2f-0.1.5 retry-decorator-1.1.1\n",
            "Collecting skorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/c7/2f6434f9360c91a4bf14ae85f634758e5dacd3539cca4266a60be9f881ae/skorch-0.9.0-py3-none-any.whl (125kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (4.41.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.8.7)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from skorch) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->skorch) (0.17.0)\n",
            "Installing collected packages: skorch\n",
            "Successfully installed skorch-0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVwItFpHDELT"
      },
      "source": [
        "# given features matrix and array with important feature indexes, this function returns the selected features\n",
        "def get_selected_features(X, f_i):\n",
        "  X_selected = []\n",
        "  for x in X:\n",
        "    selected = []\n",
        "    for i in f_i:\n",
        "      selected.append(x[i])\n",
        "    X_selected.append(selected)\n",
        "  return np.array(X_selected)\n",
        "\n",
        "# same function but this is woring with dataframes instead of numpy arrays, returns a dataframe with chosen features\n",
        "def get_selected_features_df(X_df, f_i):\n",
        "  X_selected = X_df.copy()\n",
        "  i = 0\n",
        "  for col in X_df.iloc[:, 4:]:\n",
        "    if i not in f_i: # numerical starts with 4\n",
        "      X_selected.pop(col) # drop feature column at index i \n",
        "    i += 1\n",
        "  return X_selected\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTA4GzZbDOAL"
      },
      "source": [
        "# load data - pre-processed before, we just need to load feature selection tools to use them (feature indexes, data...)\n",
        "fi = []\n",
        "train_data = []\n",
        "with open('/content/drive/My Drive/Colab Notebooks/features_indexes.data', 'rb') as f:\n",
        "  fi = pickle.load(f) \n",
        "\n",
        "# train_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/X_afterSteps_12.csv') \n",
        "train_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/train_features.csv') \n",
        "df_y = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/train_targets_scored.csv\")\n",
        "train_labels = np.array(df_y.iloc[:, 1:])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTl5ZWERGDxD",
        "outputId": "c9a0a66b-4ff6-4f4d-a5a4-6e5bd8e42b33"
      },
      "source": [
        "x = train_data.iloc[:, 2:]\n",
        "\n",
        "def encode(df, col):\n",
        "  new_df = df.copy()\n",
        "  classes = list(pd.unique(new_df.iloc[:,col]))\n",
        "  for i in range(len(df.iloc[:,col])):\n",
        "    new_df.iloc[i, col] = classes.index(new_df.iloc[i, col])\n",
        "  return new_df\n",
        "\n",
        "x=encode(x,0)\n",
        "x=encode(x,1) \n",
        "x=encode(x,2)\n",
        "print(x)\n",
        "y = df_y.iloc[:, 1:]\n",
        "X = x"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       cp_time cp_dose      g-0     g-1  ...    c-96    c-97    c-98    c-99\n",
            "0            0       0      0.0  0.5577  ... -0.3981  0.2139  0.3801  0.4176\n",
            "1            1       0      1.0  0.4087  ...  0.1522  0.1241  0.6077  0.7371\n",
            "2            2       0      2.0  0.5817  ... -0.6417 -0.2187 -1.4080  0.6931\n",
            "3            2       0      3.0 -0.2491  ... -1.6210 -0.8784 -0.3876 -0.8154\n",
            "4            1       1      4.0 -0.4009  ...  0.1094  0.2885 -0.3786  0.7125\n",
            "...        ...     ...      ...     ...  ...     ...     ...     ...     ...\n",
            "23809        0       1    527.0 -0.0636  ...  0.0631  0.9171  0.5258  0.4680\n",
            "23810        0       1   1138.0  0.3478  ... -0.2084 -0.1224 -0.2715  0.3689\n",
            "23811        2       1  14364.0  0.3756  ...  0.2256  0.7592  0.6656  0.3808\n",
            "23812        0       0  14365.0  0.2324  ...  0.1732  0.7015 -0.6290  0.0740\n",
            "23813        1       0  14366.0  1.0240  ... -3.5770 -0.4775 -2.1500 -4.2520\n",
            "\n",
            "[23814 rows x 874 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFNdK_TWYP8g"
      },
      "source": [
        "**NN before Feature Selection Code**: old code just to show and recall results on NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFYyRsZxaPKW",
        "outputId": "61cf6a5b-f6b4-41b4-97ee-a64432eca672"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# split data \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "temp = []\n",
        "for i in X_train:\n",
        "    temp.append(i) \n",
        "X_train_tensor = torch.Tensor(temp)\n",
        "\n",
        "temp = []\n",
        "for i in X_test:\n",
        "  temp.append(i)\n",
        "X_test_tensor = torch.Tensor(temp)\n",
        "y_train_tensor = torch.Tensor(y_train)\n",
        "y_test_tensor = torch.Tensor(y_test)\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(X.shape[1], 256)  \n",
        "        self.fc2 = nn.Linear(256, 1024) \n",
        "        self.fc3 = nn.Linear(1024, 512) \n",
        "        self.fc4 = nn.Linear(512, 206) \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(nn.Dropout(p=0.2)(self.fc2(x)))\n",
        "        x = F.relu(nn.Dropout(p=0.2)(self.fc3(x)))\n",
        "        x = self.fc4(x)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "nn_noFS= Net()\n",
        "print(nn_noFS)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=874, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (fc4): Linear(in_features=512, out_features=206, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTwjnZeLshnU",
        "outputId": "1510f32f-5ead-4558-87a1-58f48ae14eb3"
      },
      "source": [
        "# Pure deep NN\n",
        "\n",
        "X_train = X_train_tensor\n",
        "y_train = y_train_tensor\n",
        "X_test = X_test_tensor\n",
        "y_test = y_test_tensor\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(nn_noFS.parameters(), lr=0.001)\n",
        "\n",
        "def round_tensor(t, decimal_places=3):\n",
        "  return round(t.item(), decimal_places)\n",
        "\n",
        "def calculate_accuracy(y_true, y_pred):\n",
        "  predicted = y_pred.ge(.5).view(-1) # convert <0.5 to 0 and >0.5 to 1 (this threshold we can change it later)\n",
        "  y_true = y_true.reshape((y_true.shape[0]*y_true.shape[1],))\n",
        "  return (y_true == predicted).sum().float() / len(y_true)\n",
        "\n",
        "for epoch in range(300):\n",
        "  y_pred = nn_noFS(X_train)\n",
        "  y_pred = torch.squeeze(y_pred)\n",
        "  train_loss = criterion(y_pred, y_train)\n",
        "  if epoch % 100 == 0:\n",
        "    train_acc = calculate_accuracy(y_train, y_pred)\n",
        "    y_test_pred = nn_noFS(X_test)\n",
        "    y_test_pred = torch.squeeze(y_test_pred)\n",
        "    test_loss = criterion(y_test_pred, y_test)\n",
        "    test_acc = calculate_accuracy(y_test, y_test_pred)\n",
        "    print(\n",
        "f'''epoch {epoch}\n",
        "Train set - loss: {round_tensor(train_loss)}, accuracy: {round_tensor(train_acc)}\n",
        "Test  set - loss: {round_tensor(test_loss)}, accuracy: {round_tensor(test_acc)}\n",
        "''')\n",
        "  optimizer.zero_grad()\n",
        "  train_loss.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0\n",
            "Train set - loss: 11.385, accuracy: 0.509\n",
            "Test  set - loss: 11.456, accuracy: 0.509\n",
            "\n",
            "epoch 100\n",
            "Train set - loss: 0.237, accuracy: 0.937\n",
            "Test  set - loss: 0.237, accuracy: 0.936\n",
            "\n",
            "epoch 200\n",
            "Train set - loss: 0.144, accuracy: 0.975\n",
            "Test  set - loss: 0.144, accuracy: 0.975\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxcZFsKhyuYd",
        "outputId": "98ffaab2-ab75-4f7f-e7fc-2261db02ec44"
      },
      "source": [
        "outputs = nn_noFS(X_train_tensor)\r\n",
        "print(\"Log loss: \" + str(log_loss(y_train_tensor.detach().numpy(), outputs.detach().numpy())))\r\n",
        "\r\n",
        "outputs[outputs >= 0.5] = 1 \r\n",
        "outputs[outputs < 0.5] = 0 \r\n",
        "accuracy = (outputs == y_train_tensor).sum() / (y_train_tensor.shape[0]*y_train_tensor.shape[1]) * 100\r\n",
        "print(\"Accuracy: \" + str(accuracy) + \"%\")  \r\n",
        "\r\n",
        "f1 = f1_score(y_train_tensor.detach().numpy(), outputs.detach().numpy(), average='weighted')\r\n",
        "print(\"f1-score: \" + str(f1))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log loss: 7.874820894489429\n",
            "Accuracy: tensor(98.5397)%\n",
            "f1-score: 0.01113079059574135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvUmV7ey3u38"
      },
      "source": [
        "Again a small note, even though the accuracy is high, neural network had a very bad fscore in our project so it isn't really any better than other things we tried such as SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bk4AplOzPQQ"
      },
      "source": [
        "**NN after Feature Selection Code**: again old code, no testing yet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ednRcezszBz2"
      },
      "source": [
        "train_data = get_selected_features_df(train_data, fi)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYg_S-70zjB5",
        "outputId": "e0dbbc16-fc29-479b-a395-c7d1eec51dfb"
      },
      "source": [
        "x = train_data.iloc[:, 2:]\n",
        "\n",
        "def encode(df, col):\n",
        "  new_df = df.copy()\n",
        "  classes = list(pd.unique(new_df.iloc[:,col]))\n",
        "  for i in range(len(df.iloc[:,col])):\n",
        "    new_df.iloc[i, col] = classes.index(new_df.iloc[i, col])\n",
        "  return new_df\n",
        "\n",
        "x=encode(x,0)\n",
        "x=encode(x,1) \n",
        "x=encode(x,2)\n",
        "print(x)\n",
        "y = df_y.iloc[:, 1:]\n",
        "X = x"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       cp_time cp_dose      g-0     g-7  ...    c-96    c-97    c-98    c-99\n",
            "0            0       0      0.0 -0.0326  ... -0.3981  0.2139  0.3801  0.4176\n",
            "1            1       0      1.0  0.3372  ...  0.1522  0.1241  0.6077  0.7371\n",
            "2            2       0      2.0  0.2155  ... -0.6417 -0.2187 -1.4080  0.6931\n",
            "3            2       0      3.0  0.1792  ... -1.6210 -0.8784 -0.3876 -0.8154\n",
            "4            1       1      4.0 -0.1498  ...  0.1094  0.2885 -0.3786  0.7125\n",
            "...        ...     ...      ...     ...  ...     ...     ...     ...     ...\n",
            "23809        0       1    527.0  0.3055  ...  0.0631  0.9171  0.5258  0.4680\n",
            "23810        0       1   1138.0 -0.5565  ... -0.2084 -0.1224 -0.2715  0.3689\n",
            "23811        2       1  14364.0  0.1745  ...  0.2256  0.7592  0.6656  0.3808\n",
            "23812        0       0  14365.0  0.0463  ...  0.1732  0.7015 -0.6290  0.0740\n",
            "23813        1       0  14366.0  0.9146  ... -3.5770 -0.4775 -2.1500 -4.2520\n",
            "\n",
            "[23814 rows x 395 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQRMIRylzx09",
        "outputId": "a41026d4-f807-4486-de94-6695cfd42d01"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# split data \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "temp = []\n",
        "for i in X_train:\n",
        "    temp.append(i) \n",
        "X_train_tensor = torch.Tensor(temp)\n",
        "\n",
        "temp = []\n",
        "for i in X_test:\n",
        "  temp.append(i)\n",
        "X_test_tensor = torch.Tensor(temp)\n",
        "y_train_tensor = torch.Tensor(y_train)\n",
        "y_test_tensor = torch.Tensor(y_test)\n",
        "\n",
        "nn_FS= Net()\n",
        "print(nn_FS)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=395, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (fc4): Linear(in_features=512, out_features=206, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGjW4MZYz9gR",
        "outputId": "5ca1c387-537b-403b-d163-bd647ec90b8f"
      },
      "source": [
        "X_train = X_train_tensor\n",
        "y_train = y_train_tensor\n",
        "X_test = X_test_tensor\n",
        "y_test = y_test_tensor\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(nn_FS.parameters(), lr=0.001)\n",
        "\n",
        "def round_tensor(t, decimal_places=3):\n",
        "  return round(t.item(), decimal_places)\n",
        "\n",
        "def calculate_accuracy(y_true, y_pred):\n",
        "  predicted = y_pred.ge(.5).view(-1) # convert <0.5 to 0 and >0.5 to 1 (this threshold we can change it later)\n",
        "  y_true = y_true.reshape((y_true.shape[0]*y_true.shape[1],))\n",
        "  return (y_true == predicted).sum().float() / len(y_true)\n",
        "\n",
        "for epoch in range(300):\n",
        "  y_pred = nn_FS(X_train)\n",
        "  y_pred = torch.squeeze(y_pred)\n",
        "  train_loss = criterion(y_pred, y_train)\n",
        "  if epoch % 100 == 0:\n",
        "    train_acc = calculate_accuracy(y_train, y_pred)\n",
        "    y_test_pred = nn_FS(X_test)\n",
        "    y_test_pred = torch.squeeze(y_test_pred)\n",
        "    test_loss = criterion(y_test_pred, y_test)\n",
        "    test_acc = calculate_accuracy(y_test, y_test_pred)\n",
        "    print(\n",
        "f'''epoch {epoch}\n",
        "Train set - loss: {round_tensor(train_loss)}, accuracy: {round_tensor(train_acc)}\n",
        "Test  set - loss: {round_tensor(test_loss)}, accuracy: {round_tensor(test_acc)}\n",
        "''')\n",
        "  optimizer.zero_grad()\n",
        "  train_loss.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0\n",
            "Train set - loss: 17.003, accuracy: 0.486\n",
            "Test  set - loss: 17.011, accuracy: 0.486\n",
            "\n",
            "epoch 100\n",
            "Train set - loss: 0.173, accuracy: 0.97\n",
            "Test  set - loss: 0.174, accuracy: 0.97\n",
            "\n",
            "epoch 200\n",
            "Train set - loss: 0.123, accuracy: 0.985\n",
            "Test  set - loss: 0.124, accuracy: 0.985\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2GPLgO81BDv",
        "outputId": "1c4a6d9d-0977-4eaf-d7af-4aec32394db6"
      },
      "source": [
        "outputs = nn_FS(X_train_tensor)\r\n",
        "print(\"Log loss: \" + str(log_loss(y_train_tensor.detach().numpy(), outputs.detach().numpy())))\r\n",
        "\r\n",
        "outputs[outputs >= 0.5] = 1 \r\n",
        "outputs[outputs < 0.5] = 0 \r\n",
        "accuracy = (outputs == y_train_tensor).sum() / (y_train_tensor.shape[0]*y_train_tensor.shape[1]) * 100\r\n",
        "print(\"Accuracy: \" + str(accuracy) + \"%\")  \r\n",
        "\r\n",
        "f1 = f1_score(y_train_tensor.detach().numpy(), outputs.detach().numpy(), average='weighted')\r\n",
        "print(\"f1-score: \" + str(f1))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log loss: 10.185718847707866\n",
            "Accuracy: tensor(98.9180)%\n",
            "f1-score: 0.011261332635926246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6KqPy9kBdYE"
      },
      "source": [
        "# save models\r\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/nn_noFS.sav\", 'wb') as f:\r\n",
        "  pickle.dump(nn_noFS, f)\r\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/nn_FS.sav\", 'wb') as f:\r\n",
        "  pickle.dump(nn_FS, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pqbe-V69M6t"
      },
      "source": [
        "Slightly worse results than without FS (logloss), better accuracy though that does not mean a better model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHMp9qoI1C3h"
      },
      "source": [
        "**Compare: Hypothesis Testing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6clKJH-rHxpH"
      },
      "source": [
        "CV Scores for NO_FS (no feature selection)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7HdpApx1FHJ",
        "outputId": "eae65139-1c9f-43fe-832f-a3d9ae4647ea"
      },
      "source": [
        "# CV for no_FS (no feature seelction)\r\n",
        "\r\n",
        "# load data without FS\r\n",
        "fi = []\r\n",
        "train_data = []\r\n",
        "train_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/train_features.csv') \r\n",
        "df_y = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/train_targets_scored.csv\")\r\n",
        "train_labels = np.array(df_y.iloc[:, 1:])\r\n",
        "x = train_data.iloc[:, 2:]\r\n",
        "\r\n",
        "def encode(df, col):\r\n",
        "  new_df = df.copy()\r\n",
        "  classes = list(pd.unique(new_df.iloc[:,col]))\r\n",
        "  for i in range(len(df.iloc[:,col])):\r\n",
        "    new_df.iloc[i, col] = classes.index(new_df.iloc[i, col])\r\n",
        "  return new_df\r\n",
        "\r\n",
        "x=encode(x,0)\r\n",
        "x=encode(x,1) \r\n",
        "x=encode(x,2)\r\n",
        "print(x)\r\n",
        "y = df_y.iloc[:, 1:]\r\n",
        "X = x\r\n",
        "X_train = np.array(X)\r\n",
        "y_train = np.array(y)\r\n",
        "temp = []\r\n",
        "for i in X_train:\r\n",
        "    temp.append(i) \r\n",
        "X_train_tensor = torch.Tensor(temp)\r\n",
        "y_train_tensor = torch.Tensor(y_train)\r\n",
        "X_train = X_train_tensor\r\n",
        "y_train = y_train_tensor  \r\n",
        "\r\n",
        "criterion = nn.BCELoss()\r\n",
        "optimizer = optim.SGD(nn_FS.parameters(), lr=0.001)\r\n",
        "\r\n",
        "# model\r\n",
        "class Net(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        super(Net, self).__init__()\r\n",
        "        self.fc1 = nn.Linear(X.shape[1], 256)  \r\n",
        "        self.fc2 = nn.Linear(256, 1024) \r\n",
        "        self.fc3 = nn.Linear(1024, 512) \r\n",
        "        self.fc4 = nn.Linear(512, 206) \r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = F.relu(nn.Dropout(p=0.2)(self.fc2(x)))\r\n",
        "        x = F.relu(nn.Dropout(p=0.2)(self.fc3(x)))\r\n",
        "        x = self.fc4(x)\r\n",
        "        return torch.sigmoid(x)\r\n",
        "\r\n",
        "nn_noFS= Net()\r\n",
        "print(nn_noFS)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       cp_time cp_dose      g-0     g-1  ...    c-96    c-97    c-98    c-99\n",
            "0            0       0      0.0  0.5577  ... -0.3981  0.2139  0.3801  0.4176\n",
            "1            1       0      1.0  0.4087  ...  0.1522  0.1241  0.6077  0.7371\n",
            "2            2       0      2.0  0.5817  ... -0.6417 -0.2187 -1.4080  0.6931\n",
            "3            2       0      3.0 -0.2491  ... -1.6210 -0.8784 -0.3876 -0.8154\n",
            "4            1       1      4.0 -0.4009  ...  0.1094  0.2885 -0.3786  0.7125\n",
            "...        ...     ...      ...     ...  ...     ...     ...     ...     ...\n",
            "23809        0       1    527.0 -0.0636  ...  0.0631  0.9171  0.5258  0.4680\n",
            "23810        0       1   1138.0  0.3478  ... -0.2084 -0.1224 -0.2715  0.3689\n",
            "23811        2       1  14364.0  0.3756  ...  0.2256  0.7592  0.6656  0.3808\n",
            "23812        0       0  14365.0  0.2324  ...  0.1732  0.7015 -0.6290  0.0740\n",
            "23813        1       0  14366.0  1.0240  ... -3.5770 -0.4775 -2.1500 -4.2520\n",
            "\n",
            "[23814 rows x 874 columns]\n",
            "Net(\n",
            "  (fc1): Linear(in_features=874, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (fc4): Linear(in_features=512, out_features=206, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4hqOy6zAmzA"
      },
      "source": [
        "# since i was using pytorch for this part, i implemented my own k-fold, i was having problems with pytorch interacting with sklearn library\r\n",
        "\r\n",
        "# returns train indices\r\n",
        "def StratifiedKFold(labels, n_splits):\r\n",
        "  train = []\r\n",
        "  n = len(labels)//n_splits\r\n",
        "  for i in range(n_splits):\r\n",
        "    train.append((n*i, n*(i+1)-1))\r\n",
        "  return train\r\n",
        "\r\n",
        "n_folds = 3\r\n",
        "data, labels = X_train, y_train\r\n",
        "skf = StratifiedKFold(labels, n_splits=n_folds) "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v79P2Tyz-20u",
        "outputId": "5c871ac5-c97d-46b4-cc82-b4b431638686"
      },
      "source": [
        "# get CV scores - 100 epochs, reduced just because it was taking much time, results should be fair though since after 100 epochs we see it converges (not necessarily better with more epochs)\r\n",
        "scores_no_FS = []\r\n",
        "\r\n",
        "k = 0\r\n",
        "for (i, j) in skf:\r\n",
        "  k += 1\r\n",
        "  print(\"Running Fold\", k, \"/\", n_folds)\r\n",
        "  nn_noFS = None \r\n",
        "  nn_noFS = Net() \r\n",
        "  optimizer = optim.SGD(nn_noFS.parameters(), lr=0.001)\r\n",
        "\r\n",
        "  X_train = data[i:j]\r\n",
        "  y_train = labels[i:j]\r\n",
        "\r\n",
        "  for epoch in range(100):\r\n",
        "    y_pred = nn_noFS(X_train)\r\n",
        "    y_pred = torch.squeeze(y_pred)\r\n",
        "    train_loss = criterion(y_pred, y_train)\r\n",
        "    # if epoch % 100 == 0:\r\n",
        "      # y_test_pred = nn_noFS(X_test)\r\n",
        "      # y_test_pred = torch.squeeze(y_test_pred)\r\n",
        "      # test_loss = criterion(y_test_pred, y_test)\r\n",
        "      # test_acc = calculate_accuracy(y_test, y_test_pred)\r\n",
        "    optimizer.zero_grad()\r\n",
        "    train_loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "  train_acc = calculate_accuracy(y_train, y_pred)\r\n",
        "  scores_no_FS.append(train_acc)\r\n",
        "  print(\"Score for this fold: \" + str(train_acc))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running Fold 1 / 3\n",
            "Score for this fold: tensor(0.8947)\n",
            "Running Fold 2 / 3\n",
            "Score for this fold: tensor(0.9251)\n",
            "Running Fold 3 / 3\n",
            "Score for this fold: tensor(0.9417)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldrXhKO9H11j"
      },
      "source": [
        "CV Scores for FS (Feature Selection)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7baxVENJG8d",
        "outputId": "398f6864-8f65-4ff8-b49a-6ee10d90f681"
      },
      "source": [
        "# load data with FS\r\n",
        "fi = []\r\n",
        "train_data = []\r\n",
        "train_data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/train_features.csv') \r\n",
        "df_y = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/train_targets_scored.csv\")\r\n",
        "train_labels = np.array(df_y.iloc[:, 1:])\r\n",
        "fi = []\r\n",
        "with open('/content/drive/My Drive/Colab Notebooks/features_indexes.data', 'rb') as f:\r\n",
        "  fi = pickle.load(f) \r\n",
        "train_data = get_selected_features_df(train_data, fi) # select features\r\n",
        "x = train_data.iloc[:, 2:]\r\n",
        "\r\n",
        "def encode(df, col):\r\n",
        "  new_df = df.copy()\r\n",
        "  classes = list(pd.unique(new_df.iloc[:,col]))\r\n",
        "  for i in range(len(df.iloc[:,col])):\r\n",
        "    new_df.iloc[i, col] = classes.index(new_df.iloc[i, col])\r\n",
        "  return new_df\r\n",
        "\r\n",
        "x=encode(x,0)\r\n",
        "x=encode(x,1) \r\n",
        "x=encode(x,2)\r\n",
        "print(x)\r\n",
        "y = df_y.iloc[:, 1:]\r\n",
        "X = x\r\n",
        "X_train = np.array(X)\r\n",
        "y_train = np.array(y)\r\n",
        "temp = []\r\n",
        "for i in X_train:\r\n",
        "    temp.append(i) \r\n",
        "X_train_tensor = torch.Tensor(temp)\r\n",
        "y_train_tensor = torch.Tensor(y_train)\r\n",
        "X_train = X_train_tensor\r\n",
        "y_train = y_train_tensor  \r\n",
        "\r\n",
        "criterion = nn.BCELoss()\r\n",
        "optimizer = optim.SGD(nn_FS.parameters(), lr=0.001)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       cp_time cp_dose      g-0     g-7  ...    c-96    c-97    c-98    c-99\n",
            "0            0       0      0.0 -0.0326  ... -0.3981  0.2139  0.3801  0.4176\n",
            "1            1       0      1.0  0.3372  ...  0.1522  0.1241  0.6077  0.7371\n",
            "2            2       0      2.0  0.2155  ... -0.6417 -0.2187 -1.4080  0.6931\n",
            "3            2       0      3.0  0.1792  ... -1.6210 -0.8784 -0.3876 -0.8154\n",
            "4            1       1      4.0 -0.1498  ...  0.1094  0.2885 -0.3786  0.7125\n",
            "...        ...     ...      ...     ...  ...     ...     ...     ...     ...\n",
            "23809        0       1    527.0  0.3055  ...  0.0631  0.9171  0.5258  0.4680\n",
            "23810        0       1   1138.0 -0.5565  ... -0.2084 -0.1224 -0.2715  0.3689\n",
            "23811        2       1  14364.0  0.1745  ...  0.2256  0.7592  0.6656  0.3808\n",
            "23812        0       0  14365.0  0.0463  ...  0.1732  0.7015 -0.6290  0.0740\n",
            "23813        1       0  14366.0  0.9146  ... -3.5770 -0.4775 -2.1500 -4.2520\n",
            "\n",
            "[23814 rows x 395 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AuFXyBpH6bv",
        "outputId": "cbd442ab-49b9-4108-9c17-3173c9011238"
      },
      "source": [
        "n_folds = 3\r\n",
        "data, labels = X_train_tensor, y_train_tensor\r\n",
        "skf = StratifiedKFold(labels, n_splits=n_folds) \r\n",
        "scores_FS = []\r\n",
        "\r\n",
        "k = 0\r\n",
        "for (i, j) in skf:\r\n",
        "  k += 1\r\n",
        "  print(\"Running Fold\", k, \"/\", n_folds)\r\n",
        "  nn_noFS = None \r\n",
        "  nn_noFS = Net() \r\n",
        "  optimizer = optim.SGD(nn_noFS.parameters(), lr=0.001)\r\n",
        "\r\n",
        "  X_train = data[i:j]\r\n",
        "  y_train = labels[i:j]\r\n",
        "\r\n",
        "  for epoch in range(100):\r\n",
        "    y_pred = nn_noFS(X_train)\r\n",
        "    y_pred = torch.squeeze(y_pred)\r\n",
        "    train_loss = criterion(y_pred, y_train)\r\n",
        "    # if epoch % 100 == 0:\r\n",
        "      # y_test_pred = nn_noFS(X_test)\r\n",
        "      # y_test_pred = torch.squeeze(y_test_pred)\r\n",
        "      # test_loss = criterion(y_test_pred, y_test)\r\n",
        "      # test_acc = calculate_accuracy(y_test, y_test_pred)\r\n",
        "    optimizer.zero_grad()\r\n",
        "    train_loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "  train_acc = calculate_accuracy(y_train, y_pred)\r\n",
        "  scores_FS.append(train_acc)\r\n",
        "  print(\"Score for this fold: \" + str(train_acc))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running Fold 1 / 3\n",
            "Score for this fold: tensor(0.9380)\n",
            "Running Fold 2 / 3\n",
            "Score for this fold: tensor(0.9689)\n",
            "Running Fold 3 / 3\n",
            "Score for this fold: tensor(0.9763)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSBZv0OAH5Em"
      },
      "source": [
        "Compare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jewadg8RC4JY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f8ed771-9aad-4183-9738-317ce7655973"
      },
      "source": [
        "from scipy.stats import ttest_ind\r\n",
        "\r\n",
        "t_stat, p = ttest_ind(scores_no_FS, scores_FS)\r\n",
        "\r\n",
        "print(f'The P-value is = {p:.3f}')\r\n",
        "\r\n",
        "if p <= 0.05:\r\n",
        "    print('Since p < 0.05, rejecting the null-hypothesis that both models perform the same. The two models are significantly different.')\r\n",
        "else:\r\n",
        "    print('Since p > 0.05, we cannot reject the null hypothesis, we conclude that the performance of the two models is not significantly different.')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The P-value is = 0.088\n",
            "Since p > 0.05, we cannot reject the null hypothesis, we conclude that the performance of the two models is not significantly different.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}